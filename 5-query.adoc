:sourcedir: ../manticoresearch/src
:source-highlighter: rouge
:mermaid-puppeteer-config: config/puppeteer-config.json

== 5. 查询 / Query 

前面已经初步考察过 Sphinx 建立索引的流程和相应的主要的索引文件结构，本部分介绍在查询过程中的数据处理流程。

=== 5.1 SphinxQL 解析器 / SphinxQL Parser

Sphinx 基于 Bison / Flex 工具链定义解析器，与 SphinxQL 相关的源文件有

* searchdsql.{h|cpp} ,       实际调用解析器，构建查询抽象句法树，入口为 `sphParseSqlQuery`，返回解析好的 `SqlStmt_t` 数组

* sphinxql.l ,               词法规则，将文本识别为 Token   

* sphinxql.y ,               语法规则，将 Token 序列 构建为句法树。
* sphinxselect.y ,           Select 语句的语法规则
* ddl.{l|y} ,              创建、修改索引等 语句的语法规则


`SqlStmt_t` 在目前的版本中，实际是多种 SQL 语句的复合，根据代码中的说明，也许后续会对其进行拆分。

[source,c++]
----
include::{sourcedir}/searchdsql.h[lines=162..187]
----
[.text-center]
表 5-1：`SqlStmt_t` 的定义（片段）

. 代码中的 `m_pTableFunc`、`m_sTableFunc`、`m_dTableFuncArgs` 均与 Table Function 有关， Table function 是一类工作在结果集上的函数，目前仅存在预制函数  `REMOVE_REPEATS`，从接口的定义看，Table Function 后续可能出现较大改动。
. 结构体承载的语句 `SELECT, INSERT, DELETE, CALL, DESC, ATTACH, ALTER, RELOAD INDEX, UPDATE, CREATE/DROP`
. 具体针对 SELECT 实际的数据均包括在结构 `m_tQuery:CSphQuery` 中
. 进一步，SELECT 语句的实际解析由 `SelectParser_t` 在 `ParseSearchQuery` 中进行。

=== 5.2 查询解析器 / Query Parser 

与 SphinxQL 类似， Query Parser 也是基于 Bison / Flex 工具链。Query Parser 同时被 SphinxQL 和传统的 API 访问方式所使用。

* sphinxexpr.y ,    用户自定义表达式的支持
* sphinxquery.y ，  全文检索的查询表达式进行解析

. 在查询的过程中，可以自定义表达式，使用表达式计算后的值，在解析层面，通过 `sphExprParse` 构造 `ISphExpr` 给与支持
. SphinxQL 也应用了 `ISphExpr` 机制，以支持基于自定义表达式的字段
. sphinxquery.y 通过 `XQParser_t` 提供了对 Sphinx Extend Query 查询表达式的支持。

综合而言，一个 SphinxQL 的 Select 查询，会经过 `sphParseSqlQuery -> ParseSearchQuery -> sphExprParse -> sphParseExtendedQuery` 完成整个解析过程。

其中 `sphParseExtendedQuery` 可以将查询构造、改写为 类 Lisp 的 S 表达式形式，与 Splunk 的 实现机制类似。

[source,c++]
----
include::{sourcedir}/sphinxquery.cpp[lines=18..40]
----
[.text-center] 
表 5-2：调试开关

通过开启 `XQDEBUG` 可以对查询表达式的解析过程进行调试。

此外，针对 JSON 还有对应的解析器，此处略。

=== 5.3 查询的处理过程 / Query Processing

Sphinx 支持单次执行多个查询，这种设计主要是考虑到 分面/facet 统计的需要，这种模式中，通常会存在一个普通查询来读取结果，然后再接一个查询条件都相同的分面统计查询来进行属性的统计。搜索引擎在此模式下，可以考虑对查询结果进行缓存，但是

. 查询结果可能很大，导致无法完全缓存在内存中
. 影响搜索服务的并发访问能力

提供单次执行多个查询的能力，有利于性能优化。下面考察查询的处理逻辑。

[source,c++]
----
include::{sourcedir}/searchd.cpp[lines=15138..15174]
----
[.text-center] 
表 5-3：`CSphinxqlSession::Execute`

. 一个连接到 `searchd` 的客户端对应一个 `Session`
. 一个 `SearchHandler_c` 可以持有多个查询，存储在 `m_dQueries`
. 计算完毕后，返回 `m_dResults`
. 记录 Meta 信息

[source,c++]
----
include::{sourcedir}/searchd.cpp[lines=5100..5124]
----
[.text-center] 
表 5-4：支持对同一索引执行多个查询

. 对比索引名称，如果相同则合并处理
. `OnRunFinished` 目前仅整理了部分元信息

在 `RunSubset` 中，混合了检索 本地索引/Local Index 和 远端检索服务/Remote Agents 的 逻辑，整体的检索逻辑可以分为 3 ~ 5 步。

. [必经] 检查执行条件

* 确认是否可以同时执行多个查询，依据是各查询的检索条件均一致，在函数 `CheckMultiQuery` 中
* 确认本地的索引存在且可以获得读取的锁
* 确认查询的选出的字段是否支持 `m_bMultiQueue`，要求字段的表达式均相同。

** 此处存在优化空间，目前的实现是要求表达式的字符串值相同，但是实际执行中只需要计算任务相同即可
** 需要进一步确认 Schema On Read 模式开始时，此处的行为。

[source,c++]
----
include::{sourcedir}/searchd.cpp[lines=5783..5830]
----
[.text-center] 
表 5-4：`SearchHandler_c::AllowsMulti` 检查查询选出的字段

[start=2]
. [可选] 准备与 远端搜索服务/Remote Agent 的通信通道，如果有需要
. [必经] 执行本地的查询，通过 `RunLocalSearches`
. [可选] 等待 远端搜索服务/Remote Agent 的返回结果，如果有
. [必经] 归并检索的结果
. [可选] 执行 `TableFunc` 对结果集进行 Reform.

在进行 `RunLocalSearches` 的任务中，因为历史原因，分成两个部分，多线程 和 单线程。

* 单线程

    ** 遍历每一个索引
    ** *进行执行前准备*，创建 `ISphMatchSorter` 
    ** 执行 `MultiQuery(Ex)` 
 
* 多线程 `RunLocalSearchesParallel`

    ** 针对每个索引创建一个线程，也就是即便开启了多线程模式，仍然是一个索引一个线程
    ** *进行执行前准备*，创建 `ISphMatchSorter` 并赋值到传入的指针在 `SearchHandler_c::RunLocalSearchMT` 中
    ** 执行 `MultiQuery(Ex)` 

`ISphMatchSorter` 是非常重要的数据结构，其在执行前对查询的字段进行调整，执行后对检索结果进行排序。

[source,c++]
----
include::{sourcedir}/sphinxsort.cpp[lines=6438..6457]
...
----
[source,c++]
----
...
include::{sourcedir}/sphinxsort.cpp[lines=6569..6578]
----
[.text-center] 
表 5-5：创建 `ISphMatchSorter`

每一种不同的索引，其具体进行查询的方式也不同。 具体到 Manticore，其 三种不同的索引(Plain, RT, Percolate) 均实现了各自的 `MultiQuery(Ex)`。

其中， PlainIndex 的实现是最常见的，接下来进入 PlainIndex 的 `MultiQuery(Ex)`

在 `CSphIndex_VLN::MultiQuery` 仍然处于查询的准备阶段，

. 检查是否是有快速路径，即没有任何条件的全量扫描 
. 对查询条件进行解析后，再次检查是否仅是全量扫描
. 对 Extend Query 构造出的 AST 进行查询改写
. 扩展查询关键词
. 处理前缀查询
. 识别 AST 中的公共子树
. 调用 `ParsedMultiQuery` 执行实际的查询，其中 `CSphQueryNodeCache` 提供了对某个特定的节点（关键词） 的结果的缓存机制，从代码上看，未启用。

进入 `CSphIndex_VLN::ParsedMultiQuery` ， 整个函数比较长，分段摘录如下：

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=16105..16113]
----
. 通过 `CSphQueryProfile` 可以记录检索执行各阶段的耗时

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=16131..16141]
----
[start=2]
. 通过 `CSphQueryContext::SetupCalc` 配置需要计算的字段，以及字段计算发生的阶段

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=16198..16204]
----
[start=3]
. 通过 `sphCreateRanker` 创建一个合适的文档打分器

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=16232..16256]
----
[start=4]
. 通过 预先统计的属性信息（记录了各属性的最大值与最小值），对过滤条件进行判断，确定索引中是否可能存在符合条件的记录

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=16274..16327]
----
[start=5]
. 实际执行关键词检索并计算文档权重

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=12972..12993]
...
----

* 在 `CSphIndex_VLN::MatchExtended` 通过 `pRanker` 来执行实际的检索任务
* 提供了 pMatch 用于追踪文档的属性信息
* `GetMatches` 返回匹配的文档数量，因为结果缓冲区大小受限制，`GetMatches` 需要被调用多次
* 计算排序依赖的字段，并按属性进行过滤
* 计算文档对应的权重

[source,c++]
----
include::{sourcedir}/sphinxsearch.cpp[lines=822..848]
...
----

* 在 ` ExtRanker_State_T<STATE,USE_BM25>::GetMatches` 中通过 `GetFilteredDocs` 来获取检索出的文档
* 在 `ExtRanker_T<USE_BM25>::GetFilteredDocs` 中，通过 `GetDocsChunk` 遍历获取文档信息。
* `m_pRoot` 为 Extended Query Parser 解析出并被修正过的记录了检索意图的 AST 
** 在这个根下，根据 and or not 等逻辑关系，从小到大 遍历符合条件的 docId
** 可参考 `ExtAnd_c` , `ExtOr_c`, `ExtMaybe_c` 等的实现细节

至此，检索的执行逻辑基本执行完毕。

需要额外补充，对于计算文档权重方面在 `sphCreateRanker` 中，常见的是创建了 `ExtRanker_Expr_T`, 其实际用于计算文档权重的算法，参考其定义为 `RankerState_Expr_fn`，这一系列类需要关注下面的接口:

[source,c++]
----
...
include::{sourcedir}/sphinxsearch.cpp[lines=1874..1879]
...
----

* 对于发现的潜在的符合命中条件的文档，需要将符合条件的 Hit 信息送入 `Update`，让权重计算函数有机会更新权重计算信息；
* 调用 `Finalize` 时，会根据当前了解的 Hit 信息，计算相应的权重。


=== 5.4 自定义计算字段 / Eval 

在计算字段和排序规则两处，Sphinx 支持用户自定义公式进行扩展，因为日志检索的不需要对排序规则进行定制，下面结合自定义计算字段，分析其实现逻辑。

[source,c++]
----
include::{sourcedir}/sphinxsort.cpp[lines=6438..6457]
----
[.text-center] 
表 5-6：自定义计算字段的支持入口

. `MaybeAddGeodistColumn` 检测是否使用了 地址位置检索功能，如存在 添加字段 "@geodist"
. `MaybeAddExprColumn` 如果排序规则为用户自定义，添加字段 "@expr"
. `MaybeAddExpressionsFromSelectList` 添加其他用户自定义字段，具体的解析逻辑在 `QueueCreator_c::ParseQueryItem`

至此，系统已经知道了应该存在那些需要进行自定义计算的字段，但是这种计算字段的计算量往往很大，如果全部在检出结果后就进行计算，则当后面文档被过滤掉时，相关的计算就被浪费了。因此，Sphinx 在具体执行阶段，还引入了额外的机制来 1. 缓存计算结果，2. 避免多余的计算。

[source,c++]
----
include::{sourcedir}/sphinx.cpp[lines=14514..14606]
----
[.text-center] 
表 5-6：确定执行计算任务的阶段

[source,c++]
----
include::{sourcedir}/sphinxexpr.h[lines=61..72]
----
[.text-center] 
表 5-7：对任务执行阶段的定义

. 通过 `GetEarliestStage` 确定字段的值被使用的最早阶段
. 具体 计算阶段 及其发生的时间在代码注释中有说明

后面在 SchemaOnRead 中，会对如何计算字段的依赖关系有进一步展开。
